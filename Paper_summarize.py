import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF
import xlsxwriter
import io
import json
from PIL import Image

# -----------------------------------------------------------
# [1] í˜ì´ì§€ ì„¤ì •
# -----------------------------------------------------------
st.set_page_config(page_title="ë…¼ë¬¸ ë¶„ì„ Pro", layout="wide")

# -----------------------------------------------------------
# [2] ë©”ì¸ UI
# -----------------------------------------------------------
st.title("ğŸ“‘ ë…¼ë¬¸ ë¶„ì„ Pro [ver10.1 - Vision + Custom Model]")
st.caption("âœ… ë”¥ëŸ¬ë‹ ë¹„ì „ ì¸ì‹(ì¢Œí‘œ ì¶”ì¶œ) | ëª¨ë¸ ì„ íƒ ê¸°ëŠ¥ ë³µêµ¬ (2.5-flash ë“± ììœ  ì„ íƒ)")

# -----------------------------------------------------------
# [3] ì‚¬ì´ë“œë°”
# -----------------------------------------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    default_key = ''
    api_key_input = st.text_input("Google API Key", value=default_key, type="password")

    if not api_key_input:
        st.warning("ğŸ‘ˆ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    genai.configure(api_key=api_key_input, transport='rest')

    st.subheader("ğŸ¤– AI ëª¨ë¸ ì„ íƒ")
    try:
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.replace('models/', '')
                available_models.append(name)

        # ì‚¬ìš©ìê°€ ì„ í˜¸í–ˆë˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (2.5-flash ìš°ì„ )
        preferred = ['gemini-2.5-flash', 'gemini-1.5-flash', 'gemini-1.5-pro']
        available_models.sort(key=lambda x: (x not in preferred, x))

        selected_model_name = st.selectbox(
            "âœ… ëª¨ë¸ ì„ íƒ (2.5-flash ê¸°ë³¸)",
            available_models,
            index=0
        )
        SELECTED_MODEL_NAME = f"models/{selected_model_name}"
        st.success(f"ì—°ê²°ë¨: {selected_model_name}")

        # ëª¨ë¸ë³„ íŒ í‘œì‹œ
        if "pro" in selected_model_name:
            st.info("ğŸ’¡ Pro ëª¨ë¸: ì†ë„ëŠ” ëŠë¦¬ì§€ë§Œ ê·¸ë¦¼ ìœ„ì¹˜ë¥¼ ë” ì •í™•í•˜ê²Œ ì°¾ìŠµë‹ˆë‹¤.")
        else:
            st.info("âš¡ Flash ëª¨ë¸: ì†ë„ê°€ ë¹ ë¦…ë‹ˆë‹¤.")

    except Exception as e:
        st.error(f"ëª¨ë¸ ëª©ë¡ ì˜¤ë¥˜: {e}")
        st.stop()

model = genai.GenerativeModel(SELECTED_MODEL_NAME)


# -----------------------------------------------------------
# [4] í•µì‹¬ ë¡œì§: AI Visionì„ ì´ìš©í•œ ì¢Œí‘œ ì¶”ì¶œ
# -----------------------------------------------------------
def detect_regions_with_gemini(page_image):
    """
    í˜ì´ì§€ ì´ë¯¸ì§€ë¥¼ Geminiì—ê²Œ ë³´ë‚´ì„œ Figureì™€ Tableì˜ ì¢Œí‘œë¥¼ ë°›ì•„ì˜´.
    """
    prompt = """
    Look at this research paper page. 
    Detect all **Figures (charts, diagrams, photos)** and **Tables**.

    [Rules]
    1. Return Bounding Boxes in **normalized coordinates (0 to 1000)**: [ymin, xmin, ymax, xmax].
    2. **Include Captions:** The bounding box MUST include the Figure/Table label (e.g., "Fig. 1", "Table 1") and its description text.
    3. **Group Together:** If a figure has multiple parts (a, b, c) and one caption, group them into ONE bounding box.
    4. **Output Format:** JSON list of objects.

    Example Output:
    [
      {"type": "Figure", "label": "Fig. 1", "box_2d": [100, 50, 400, 500]},
      {"type": "Table", "label": "Table 1", "box_2d": [500, 50, 700, 950]}
    ]
    """

    try:
        response = model.generate_content(
            [prompt, page_image],
            generation_config={"response_mime_type": "application/json"}
        )
        return json.loads(response.text)
    except:
        return []


def extract_data_from_pdf(uploaded_file):
    pdf_bytes = uploaded_file.getvalue()
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")

    final_text_content = ""
    image_counter = 1

    all_page_images = []
    extracted_images_map = {}

    # ì§„í–‰ë¥  í‘œì‹œ ë°”
    progress_bar = st.progress(0)
    status_text = st.empty()
    total_pages = len(doc)

    for page_num, page in enumerate(doc):
        # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
        status_text.text(f"ğŸ” AIê°€ {page_num + 1}/{total_pages} í˜ì´ì§€ë¥¼ ë³´ê³  ìˆìŠµë‹ˆë‹¤...")
        progress_bar.progress((page_num + 1) / total_pages)

        # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìš”ì•½ìš©)
        final_text_content += page.get_text() + "\n"

        # 2. í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (AI ë¶„ì„ìš©)
        # í•´ìƒë„ë¥¼ ë†’ì—¬ì•¼(dpi=200 ì´ìƒ) ì‘ì€ ê¸€ì”¨ë„ ì˜ ë³´ì„
        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
        img_data_bytes = pix.tobytes("png")
        pil_image = Image.open(io.BytesIO(img_data_bytes))
        all_page_images.append(pil_image)

        # 3. [Deep Learning] AIì—ê²Œ ì¢Œí‘œ ìš”ì²­
        # ë¹„ì „ ê¸°ëŠ¥ì´ ìˆëŠ” ëª¨ë¸ì¸ì§€ í™•ì¸ í›„ ìš”ì²­
        detected_objects = detect_regions_with_gemini(pil_image)

        page_width = page.rect.width
        page_height = page.rect.height

        # 4. AIê°€ ì•Œë ¤ì¤€ ì¢Œí‘œëŒ€ë¡œ ìë¥´ê¸°
        if detected_objects:
            for obj in detected_objects:
                label = obj.get("label", "Unknown")
                box = obj.get("box_2d")  # [ymin, xmin, ymax, xmax] (0~1000)

                if not box: continue

                # ì¢Œí‘œ ì •ê·œí™” (0~1000 -> ì‹¤ì œ PDF ì¢Œí‘œ)
                # Gemini Visionì€ [ymin, xmin, ymax, xmax] ìˆœì„œë¡œ ì¤Œ
                ymin, xmin, ymax, xmax = box

                real_x0 = (xmin / 1000) * page_width
                real_y0 = (ymin / 1000) * page_height
                real_x1 = (xmax / 1000) * page_width
                real_y1 = (ymax / 1000) * page_height

                # ì¢Œí‘œ ìœ íš¨ì„± ê²€ì‚¬ ë° ì—¬ìœ  ê³µê°„(Padding) ì¶”ê°€
                pad = 10
                crop_rect = fitz.Rect(
                    max(0, real_x0 - pad),
                    max(0, real_y0 - pad),
                    min(page_width, real_x1 + pad),
                    min(page_height, real_y1 + pad)
                )

                if crop_rect.width < 50 or crop_rect.height < 50: continue

                try:
                    # ê³ í•´ìƒë„ ìº¡ì²˜
                    clip_pix = page.get_pixmap(matrix=fitz.Matrix(2, 2), clip=crop_rect)
                    img_bytes = clip_pix.tobytes("png")

                    img_id = f"Image_{image_counter}"
                    image_counter += 1

                    extracted_images_map[img_id] = {
                        "id": img_id,
                        "page": page_num + 1,
                        "bytes": img_bytes,
                        "initial_label": label,  # AIê°€ ì½ì€ ë¼ë²¨ (ì˜ˆ: Fig. 1)
                        "real_label": label
                    }
                except Exception as e:
                    print(f"Crop Error: {e}")
                    continue

    status_text.text("âœ… ë¶„ì„ ì™„ë£Œ! ì—‘ì…€ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    progress_bar.empty()

    extracted_images = list(extracted_images_map.values())
    return final_text_content, extracted_images, all_page_images


def get_gemini_analysis(text, total_images, all_page_images):
    prompt = f"""
    ë„ˆëŠ” ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì•„ë˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‚´ìš©ì„ í•œêµ­ì–´ë¡œ ìš”ì•½í•´.

    [ì§€ì‹œì‚¬í•­]
    1. ìš”ì•½(intro, body, conclusion)ì€ ë°˜ë“œì‹œ 'í•œêµ­ì–´(Korean)'ë¡œ ê°œì¡°ì‹ ì‘ì„±.
    2. `referenced_images`ì˜ `real_label`ì€ í…ìŠ¤íŠ¸ì˜ ë²ˆí˜¸(ì˜ˆ: Fig 1, Table 1)ì™€ ì¼ì¹˜ì‹œí‚¬ ê²ƒ.
    3. ì´ë¯¸ì§€ê°€ ë³¸ë¬¸ ë‚´ìš©ì—ì„œ ì–´ë–¤ ì˜ë¯¸ë¥¼ ê°–ëŠ”ì§€ `caption`ì— ìƒì„¸íˆ ì ì–´ì¤˜.

    [JSON í˜•ì‹]
    {{
        "title": "ì œëª©", "author": "ì €ì", "affiliation": "ì†Œì†", "year": "ì—°ë„", "purpose": "ëª©ì ",
        "intro_summary": "- ...",
        "body_summary": "- ...",
        "conclusion_summary": "- ...",
        "key_images_desc": "ì£¼ìš” ê·¸ë¦¼ ì„¤ëª… ìš”ì•½",
        "referenced_images": [ {{ "img_id": "Image_1", "real_label": "Fig. 1", "caption": "í•œêµ­ì–´ ì„¤ëª…" }} ]
    }}
    """
    inputs = [prompt]
    # í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ë³´ëƒ„
    if len(text.strip()) > 500:
        inputs.append(f"[Text Data]:\n{text[:50000]}")
    else:
        inputs.append("í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.")

    try:
        response = model.generate_content(inputs, generation_config={"response_mime_type": "application/json"})
        return json.loads(response.text)
    except Exception as e:
        return {"error": str(e)}


# -----------------------------------------------------------
# [6] ì—‘ì…€ ìƒì„± ë° ìœ í‹¸ë¦¬í‹° (ê¸°ì¡´ê³¼ ë™ì¼í•˜ì§€ë§Œ ì•ˆì •ì„± ê°•í™”)
# -----------------------------------------------------------
def standardize_label_to_korean(label_text):
    if not label_text: return ("Unknown", 999, "ë¯¸ë¶„ë¥˜")
    label_upper = str(label_text).upper()
    detected_type = "Figure"
    korean_prefix = "ê·¸ë¦¼"

    if "TAB" in label_upper or "í‘œ" in label_upper:
        detected_type = "Table"
        korean_prefix = "í‘œ"
    elif "FIG" in label_upper or "ê·¸ë¦¼" in label_upper:
        detected_type = "Figure"
        korean_prefix = "ê·¸ë¦¼"

    import re
    nums = re.findall(r'\d+', label_text)
    if nums:
        detected_num = int(nums[0])
        final_label = f"{korean_prefix} {detected_num}"
    else:
        detected_num = 999
        final_label = f"{korean_prefix} (ë²ˆí˜¸ ì—†ìŒ)"
    return (detected_type, detected_num, final_label)


def create_excel(paper_number, analysis_json, images, final_figures, final_tables):
    output = io.BytesIO()
    workbook = xlsxwriter.Workbook(output, {'in_memory': True})

    header_style = workbook.add_format(
        {'bold': True, 'bg_color': '#4472C4', 'font_color': 'white', 'border': 1, 'align': 'center',
         'valign': 'vcenter'})
    content_style = workbook.add_format({'text_wrap': True, 'valign': 'top', 'border': 1})
    fig_style = workbook.add_format(
        {'bold': True, 'valign': 'center', 'border': 1, 'bg_color': '#E7E6E6', 'align': 'center'})
    tbl_style = workbook.add_format(
        {'bold': True, 'valign': 'center', 'border': 1, 'bg_color': '#D9D9D9', 'align': 'center'})

    ws1 = workbook.add_worksheet("ë…¼ë¬¸ í•µì‹¬ ë¶„ì„")
    ws1.set_column('A:A', 25)
    ws1.set_column('B:B', 90)

    data_map = [
        ("No.", paper_number),
        ("ë…¼ë¬¸ ì œëª©", analysis_json.get('title', '-')),
        ("ì €ì", analysis_json.get('author', '-')),
        ("ì €ì ì†Œì†", analysis_json.get('affiliation', '-')),
        ("ë°œí–‰ë…„ë„", analysis_json.get('year', '-')),
        ("ì—°êµ¬ ëª©ì ", analysis_json.get('purpose', '-')),
        ("ì„œë¡  ìš”ì•½", analysis_json.get('intro_summary', '-')),
        ("ë³¸ë¡  ìš”ì•½", analysis_json.get('body_summary', '-')),
        ("ê²°ë¡  ìš”ì•½", analysis_json.get('conclusion_summary', '-')),
        ("ì£¼ìš” í‘œ/ê·¸ë¦¼ ì„¤ëª…", analysis_json.get('key_images_desc', '-'))
    ]

    ws1.write(0, 0, "í•­ëª©", header_style)
    ws1.write(0, 1, "ë‚´ìš©", header_style)

    current_row = 1
    for label, content in data_map:
        if isinstance(content, list):
            content = "\n".join(map(str, content))
        elif content is None:
            content = "-"
        ws1.write(current_row, 0, label, header_style)
        ws1.write(current_row, 1, str(content), content_style)
        current_row += 1

    def write_section(title, items, style):
        nonlocal current_row
        if not items: return
        current_row += 1
        ws1.write(current_row, 0, title, header_style)
        ws1.write(current_row, 1, f"â–¼ ì£¼ìš” {title} ëª©ë¡", header_style)
        current_row += 1

        for item in items:
            clean_id = item.get('img_id')
            target = next((img for img in images if img['id'] == clean_id), None)

            final_label = item.get('korean_label', item.get('real_label', 'ê·¸ë¦¼'))
            caption_text = item.get('caption', 'ì„¤ëª… ì—†ìŒ')

            ws1.write(current_row, 0, str(final_label), style)
            ws1.write(current_row, 1, f"ğŸ“„ {str(caption_text)}", content_style)

            img_row = current_row + 1
            if target:
                try:
                    with Image.open(io.BytesIO(target['bytes'])) as img:
                        w_px, h_px = img.size

                    # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (ì—‘ì…€ ì…€ ë†’ì´ ì¡°ì ˆ)
                    scale = 0.5
                    display_h = h_px * scale
                    row_h = display_h * 0.75

                    if row_h > 400:
                        row_h = 400
                        scale = (400 / 0.75) / h_px

                    ws1.set_row(img_row, row_h)
                    ws1.insert_image(img_row, 1, f"{clean_id}.png", {
                        'image_data': io.BytesIO(target['bytes']),
                        'x_scale': scale, 'y_scale': scale,
                        'x_offset': 5, 'y_offset': 5, 'object_position': 1
                    })
                except:
                    pass
            current_row += 2

    write_section("ê·¸ë¦¼ (Figures)", final_figures, fig_style)
    write_section("í‘œ (Tables)", final_tables, tbl_style)

    workbook.close()
    output.seek(0)
    return output


# -----------------------------------------------------------
# [7] ì‹¤í–‰ ë¡œì§
# -----------------------------------------------------------

if 'analyzed_data' not in st.session_state:
    st.session_state.analyzed_data = None

paper_num = st.text_input("1. ë…¼ë¬¸ ë²ˆí˜¸ ì…ë ¥", value="1")
uploaded_file = st.file_uploader("2. PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

if uploaded_file and paper_num:
    if st.session_state.analyzed_data and st.session_state.analyzed_data['file_name'] != uploaded_file.name:
        st.session_state.analyzed_data = None

    if st.button("ë¶„ì„ ë° ì—‘ì…€ ë³€í™˜ ì‹œì‘"):
        # ì§„í–‰ ì¤‘ ìƒíƒœ í‘œì‹œ
        if st.session_state.analyzed_data and st.session_state.analyzed_data['file_name'] == uploaded_file.name:
            st.success("âš¡ ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
        else:
            with st.spinner(f"[{SELECTED_MODEL_NAME}] AIê°€ ëˆˆìœ¼ë¡œ ë³´ê³  ë¶„ì„ ì¤‘... (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦½ë‹ˆë‹¤)"):
                try:
                    # 1. ì´ë¯¸ì§€ ì¶”ì¶œ (AI Vision ì‚¬ìš©)
                    text, images, all_page_imgs = extract_data_from_pdf(uploaded_file)

                    if not images:
                        st.warning("âš ï¸ AIê°€ ê·¸ë¦¼/í‘œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ '1.5-pro'ë¡œ ë³€ê²½í•´ë³´ì„¸ìš”.")
                    else:
                        st.info(f"âœ… AIê°€ {len(images)}ê°œì˜ ê·¸ë¦¼/í‘œ ì˜ì—­ì„ ì¸ì‹í–ˆìŠµë‹ˆë‹¤!")

                    # 2. ë‚´ìš© ë¶„ì„
                    result = get_gemini_analysis(text, len(images), all_page_imgs)

                    if "error" in result:
                        st.error(f"AI ë¶„ì„ ì˜¤ë¥˜: {result['error']}")
                    else:
                        # 3. ë§¤ì¹­ ë° ì •ë ¬
                        ref_imgs = result.get('referenced_images', [])

                        final_figs, final_tbls = [], []

                        for img in images:
                            img_label = img['initial_label']  # Visionì´ ì½ì€ ë¼ë²¨ (ì˜ˆ: Fig 1)

                            # ë¶„ì„ ê²°ê³¼ì—ì„œ ì„¤ëª… ì°¾ê¸°
                            matched_caption = "ì„¤ëª… ì—†ìŒ"
                            for ref in ref_imgs:
                                # ë‹¨ìˆœ í¬í•¨ ê´€ê³„ í™•ì¸ (Fig 1 in Figure 1)
                                # AIê°€ ì½ì€ ë¼ë²¨ê³¼ ë¶„ì„ëœ ë¼ë²¨ì„ ìµœëŒ€í•œ ë§¤ì¹­
                                if normalize_id(img_label) == normalize_id(ref.get('real_label', '')):
                                    matched_caption = ref.get('caption', '-')
                                    break

                            # ë¶„ë¥˜ ë° ì €ì¥
                            d_type, d_num, k_label = standardize_label_to_korean(img_label)

                            item = {
                                'img_id': img['id'],
                                'real_label': img_label,
                                'korean_label': k_label,
                                'caption': matched_caption,
                                'sort_num': d_num
                            }

                            if d_type == 'Table':
                                final_tbls.append(item)
                            else:
                                final_figs.append(item)

                        final_figs.sort(key=lambda x: x['sort_num'])
                        final_tbls.sort(key=lambda x: x['sort_num'])

                        st.session_state.analyzed_data = {
                            'file_name': uploaded_file.name,
                            'json': result,
                            'images': images,
                            'figs': final_figs,
                            'tbls': final_tbls
                        }
                        st.success("ì™„ë£Œ! AIê°€ ë³´ê³  íŒë‹¨í•œ ê²°ê³¼ì…ë‹ˆë‹¤.")

                except Exception as e:
                    st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")

    if st.session_state.analyzed_data:
        data = st.session_state.analyzed_data
        excel_data = create_excel(paper_num, data['json'], data['images'], data['figs'], data['tbls'])

        st.download_button(
            label="ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"Analysis_v10.1_{paper_num}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
