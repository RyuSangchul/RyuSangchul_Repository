import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF
import xlsxwriter
import io
import json
import re
from PIL import Image

# -----------------------------------------------------------
# [1] í˜ì´ì§€ ì„¤ì •
# -----------------------------------------------------------
st.set_page_config(page_title="ë…¼ë¬¸ ë¶„ì„ Pro", layout="wide")

# -----------------------------------------------------------
# [2] ë©”ì¸ UI
# -----------------------------------------------------------
st.title("ğŸ“‘ ë…¼ë¬¸ ë¶„ì„ Pro [ver6.6 - Smart Crop]")
st.caption("âœ… ë¡œê³ /ì•„ì´ì½˜ ìë™ ì œê±° | ìº¡ì…˜ ìœ„ì¹˜ ê¸°ë°˜ 'ì˜ì—­ ìº¡ì²˜'ë¡œ ì •í™•ë„ í–¥ìƒ | ìš”ì•½ í•œê¸€ í•„ìˆ˜")

# -----------------------------------------------------------
# [3] ì‚¬ì´ë“œë°”
# -----------------------------------------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    default_key = ''
    api_key_input = st.text_input("Google API Key", value=default_key, type="password")

    if not api_key_input:
        st.warning("ğŸ‘ˆ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    genai.configure(api_key=api_key_input, transport='rest')

    st.subheader("ğŸ¤– AI ëª¨ë¸ ì„ íƒ")
    try:
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.replace('models/', '')
                available_models.append(name)

        preferred = ['gemini-2.5-flash', 'gemini-1.5-flash']
        available_models.sort(key=lambda x: (x not in preferred, x))

        selected_model_name = st.selectbox(
            "âœ… ëª¨ë¸ ì„ íƒ (2.5-flash ê¸°ë³¸)",
            available_models,
            index=0
        )
        SELECTED_MODEL_NAME = f"models/{selected_model_name}"
        st.success(f"ì—°ê²°ë¨: {selected_model_name}")

    except Exception as e:
        st.error(f"ëª¨ë¸ ëª©ë¡ ì˜¤ë¥˜: {e}")
        st.stop()

model = genai.GenerativeModel(SELECTED_MODEL_NAME)


# -----------------------------------------------------------
# [4] ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# -----------------------------------------------------------
def normalize_id(ref_text):
    nums = re.findall(r'\d+', str(ref_text))
    return f"Image_{nums[0]}" if nums else None


def standardize_label_to_korean(label_text):
    """
    ë¼ë²¨ì„ ë¶„ì„í•´ì„œ í•œê¸€ë¡œ ë³€í™˜ (Figure 1 -> ê·¸ë¦¼ 1)
    """
    if not label_text:
        return ("Unknown", 999, "ë¯¸ë¶„ë¥˜")

    label_upper = str(label_text).upper()

    # 1. íƒ€ì… ê²°ì • ë° í•œê¸€ ë³€í™˜
    detected_type = "Figure"
    korean_prefix = "ê·¸ë¦¼"

    if "TAB" in label_upper or "í‘œ" in label_upper:
        detected_type = "Table"
        korean_prefix = "í‘œ"
    elif "FIG" in label_upper or "ê·¸ë¦¼" in label_upper:
        detected_type = "Figure"
        korean_prefix = "ê·¸ë¦¼"

    # 2. ë²ˆí˜¸ ì¶”ì¶œ
    nums = re.findall(r'\d+', label_text)
    if nums:
        detected_num = int(nums[0])
        final_label = f"{korean_prefix} {detected_num}"
    else:
        detected_num = 999
        final_label = f"{korean_prefix} (ë²ˆí˜¸ ì—†ìŒ)"

    return (detected_type, detected_num, final_label)


# -----------------------------------------------------------
# [5] í•µì‹¬ ë¡œì§ í•¨ìˆ˜ (ì™„ì „íˆ ìƒˆë¡œ ì‘ì„±ë¨)
# -----------------------------------------------------------
def extract_data_from_pdf(uploaded_file):
    pdf_bytes = uploaded_file.getvalue()
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")

    final_text_content = ""
    image_counter = 1

    all_page_images = []  # í…ìŠ¤íŠ¸ ì¸ì‹ ì‹¤íŒ¨ ëŒ€ë¹„ìš©
    extracted_images_map = {}  # ìµœì¢… ì´ë¯¸ì§€ ì €ì¥ì†Œ

    for page_num, page in enumerate(doc):
        # 1. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text_blocks = page.get_text("blocks")
        for b in text_blocks:
            final_text_content += b[4].strip() + "\n"

        # 2. í˜ì´ì§€ ì „ì²´ ì´ë¯¸ì§€ ì €ì¥ (AI ë¶„ì„ìš©)
        pix = page.get_pixmap(matrix=fitz.Matrix(1.5, 1.5))
        img_data = Image.open(io.BytesIO(pix.tobytes("png")))
        all_page_images.append(img_data)

        # 3. [í•µì‹¬] ìº¡ì…˜ í…ìŠ¤íŠ¸ ì°¾ê¸° (Fig, Table)
        # í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ìˆœíšŒí•˜ë©° "Fig"ë‚˜ "Table"ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì„ ì°¾ìŒ
        captions = []
        for b in text_blocks:
            text = b[4].strip()
            # ìº¡ì…˜ ì¡°ê±´: Fig/Tableë¡œ ì‹œì‘í•˜ê³  ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì§€ ì•Šì€ ê²ƒ
            if re.match(r"^(Fig|Figure|Table|ê·¸ë¦¼|í‘œ)\s*\.?\s*\d+", text, re.IGNORECASE) and len(text) < 300:
                bbox = fitz.Rect(b[0], b[1], b[2], b[3])
                captions.append({"text": text, "bbox": bbox})

        # 4. [í•µì‹¬] ìº¡ì…˜ ê¸°ì¤€ìœ¼ë¡œ ì˜ì—­ ìº¡ì²˜ (Smart Crop)
        # ì´ë¯¸ì§€ë¥¼ ì°¾ëŠ” ê²Œ ì•„ë‹ˆë¼, ìº¡ì…˜ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í™”ë©´ì„ ì˜ë¼ë²„ë¦¼
        for cap in captions:
            text = cap["text"]
            bbox = cap["bbox"]

            is_table = "Table" in text or "í‘œ" in text
            img_id = f"Image_{image_counter}"
            image_counter += 1

            # ì˜ë¼ë‚¼ ì˜ì—­ ê³„ì‚° (Crop Area)
            page_rect = page.rect
            crop_rect = None

            if is_table:
                # í‘œëŠ” ìº¡ì…˜ì´ ë³´í†µ 'ìœ„'ì— ìˆìŒ -> ìº¡ì…˜ 'ì•„ë˜'ë¥¼ ìº¡ì²˜
                # ìº¡ì…˜ y1ë¶€í„° í˜ì´ì§€ ë í˜¹ì€ ì ë‹¹í•œ ë†’ì´(300~400px)ê¹Œì§€
                crop_rect = fitz.Rect(page_rect.x0 + 30, bbox.y1, page_rect.x1 - 30,
                                      min(bbox.y1 + 400, page_rect.y1 - 50))
            else:
                # ê·¸ë¦¼ì€ ìº¡ì…˜ì´ ë³´í†µ 'ì•„ë˜'ì— ìˆìŒ -> ìº¡ì…˜ 'ìœ„'ë¥¼ ìº¡ì²˜
                # ìº¡ì…˜ y0ì—ì„œ ìœ„ë¡œ 300~400px ì •ë„
                crop_rect = fitz.Rect(page_rect.x0 + 30, max(bbox.y0 - 400, page_rect.y0 + 50), page_rect.x1 - 30,
                                      bbox.y0)

            # ì˜ì—­ ìº¡ì²˜ ì‹¤í–‰
            try:
                clip_pix = page.get_pixmap(matrix=fitz.Matrix(2, 2), clip=crop_rect)

                # [ì¤‘ìš”] ìº¡ì²˜í•œ ì´ë¯¸ì§€ê°€ ë„ˆë¬´ ë‹¨ìƒ‰ì´ê±°ë‚˜(í°ìƒ‰) ì‘ìœ¼ë©´ ë²„ë¦¼ (ë¹ˆ ê³µê°„ ë°©ì§€)
                if clip_pix.width < 50 or clip_pix.height < 50:
                    continue

                img_bytes = clip_pix.tobytes("png")

                # ë¼ë²¨ ì •ê·œí™” (Fig. 1 -> ê·¸ë¦¼ 1)
                label_match = re.match(r"(Fig\.?|Figure|Table|ê·¸ë¦¼|í‘œ)\s*\d+", text, re.IGNORECASE)
                real_label = label_match.group(0) if label_match else text[:10]

                extracted_images_map[img_id] = {
                    "id": img_id,
                    "page": page_num + 1,
                    "bytes": img_bytes,
                    "initial_label": text,  # ì „ì²´ ìº¡ì…˜
                    "real_label": real_label  # ê·¸ë¦¼ 1
                }
            except Exception as e:
                print(f"Crop Error: {e}")
                continue

    extracted_images = list(extracted_images_map.values())
    return final_text_content, extracted_images, all_page_images


def get_gemini_analysis(text, total_images, all_page_images):
    inputs = []

    # [í”„ë¡¬í”„íŠ¸ ê°•í™”] í•œêµ­ì–´ ìš”ì•½ í•„ìˆ˜ & ì´ë¯¸ì§€ ë§¤ì¹­ ì§€ì‹œ
    prompt = f"""
    ë„ˆëŠ” í•œêµ­ì–´ ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì œê³µëœ ìë£Œë¥¼ ë³´ê³  JSONì„ ì¶”ì¶œí•´.

    [ì ˆëŒ€ ê·œì¹™]
    1. **ëª¨ë“  ìš”ì•½(Summary)ì€ ë°˜ë“œì‹œ 'í•œêµ­ì–´(Korean)'ë¡œ ë²ˆì—­í•´ì„œ ì‘ì„±í•´.** (ì˜ì–´ ë‚´ìš© ê¸ˆì§€)
    2. **ìš”ì•½ì€ 'ê°œì¡°ì‹(Bullet Points)'ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´.**
    3. **ì´ë¯¸ì§€ ë§¤ì¹­:**
       - ë‚´ê°€ ì¶”ì¶œí•œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸(`referenced_images`)ì— ìˆëŠ” `real_label` (ì˜ˆ: ê·¸ë¦¼ 1)ê³¼ ë‚´ìš©ì„ ë§¤ì¹­í•´ì„œ ì„¤ëª…í•´.
       - ì—‰ëš±í•œ ì´ë¯¸ì§€ë¥¼ ë§¤ì¹­í•˜ì§€ ë§ˆ.

    [ìš”ì²­ í•­ëª©]
    0. title, author, affiliation, year, purpose
    1. ìš”ì•½ (intro_summary, body_summary, conclusion_summary) - **í•œêµ­ì–´ í•„ìˆ˜**
    2. key_images_desc - **í•œêµ­ì–´ í•„ìˆ˜**
    3. referenced_images (ì´ë¯¸ì§€ IDì™€ ì„¤ëª…ì„ ìœ ì§€í•´)

    [ì¶œë ¥ í¬ë§· JSON]
    {{
        "title": "...",
        "author": "...", "affiliation": "...", "year": "...", "purpose": "...",
        "intro_summary": "- ...", 
        "body_summary": "- ...", 
        "conclusion_summary": "- ...",
        "key_images_desc": "...",
        "referenced_images": [ 
            {{ "img_id": "Image_1", "real_label": "Figure 1", "caption": "í•œêµ­ì–´ ì„¤ëª…" }}
        ]
    }}
    """

    inputs.append(prompt)

    is_text_valid = len(text.strip()) > 500

    if is_text_valid:
        inputs.append(f"[ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë°ì´í„°]:\n{text[:50000]}")
    else:
        inputs.append("[ì‹œìŠ¤í…œ ì•Œë¦¼: í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨. ì•„ë˜ì˜ 'ì „ì²´ í˜ì´ì§€ ì´ë¯¸ì§€'ë¥¼ ë³´ê³  ë‚´ìš©ì„ ìš”ì•½í•˜ì„¸ìš”.]")

    # í…ìŠ¤íŠ¸ê°€ ë¶€ì¡±í•  ë•Œë§Œ ì „ì²´ í˜ì´ì§€ ì´ë¯¸ì§€ ì „ì†¡ (ë¹„ìš©/ì†ë„ ì ˆì•½)
    if not is_text_valid:
        max_pages = 30
        for i, img in enumerate(all_page_images[:max_pages]):
            inputs.append(f"Page {i + 1} Image:")
            inputs.append(img)

    try:
        response = model.generate_content(inputs, generation_config={"response_mime_type": "application/json"})
        return json.loads(response.text)
    except Exception as e:
        return {"error": str(e)}


def create_excel(paper_number, analysis_json, images, final_figures, final_tables):
    output = io.BytesIO()
    workbook = xlsxwriter.Workbook(output, {'in_memory': True})

    header_style = workbook.add_format(
        {'bold': True, 'bg_color': '#4472C4', 'font_color': 'white', 'border': 1, 'align': 'center',
         'valign': 'vcenter'})
    content_style = workbook.add_format({'text_wrap': True, 'valign': 'top', 'border': 1})
    fig_style = workbook.add_format(
        {'bold': True, 'valign': 'center', 'border': 1, 'bg_color': '#E7E6E6', 'align': 'center'})
    tbl_style = workbook.add_format(
        {'bold': True, 'valign': 'center', 'border': 1, 'bg_color': '#D9D9D9', 'align': 'center'})

    ws1 = workbook.add_worksheet("ë…¼ë¬¸ í•µì‹¬ ë¶„ì„")
    ws1.set_column('A:A', 25)
    ws1.set_column('B:B', 90)

    data_map = [
        ("No.", paper_number),
        ("ë…¼ë¬¸ ì œëª©", analysis_json.get('title', '-')),
        ("ì €ì", analysis_json.get('author', '-')),
        ("ì €ì ì†Œì†", analysis_json.get('affiliation', '-')),
        ("ë°œí–‰ë…„ë„", analysis_json.get('year', '-')),
        ("ì—°êµ¬ ëª©ì ", analysis_json.get('purpose', '-')),
        ("ì„œë¡  ìš”ì•½", analysis_json.get('intro_summary', '-')),
        ("ë³¸ë¡  ìš”ì•½", analysis_json.get('body_summary', '-')),
        ("ê²°ë¡  ìš”ì•½", analysis_json.get('conclusion_summary', '-')),
        ("ì£¼ìš” í‘œ/ê·¸ë¦¼ ì„¤ëª…", analysis_json.get('key_images_desc', '-'))
    ]

    ws1.write(0, 0, "í•­ëª©", header_style)
    ws1.write(0, 1, "ë‚´ìš©", header_style)

    current_row = 1
    for label, content in data_map:
        if isinstance(content, list):
            content = "\n".join(map(str, content))
        elif content is None:
            content = "-"
        ws1.write(current_row, 0, label, header_style)
        ws1.write(current_row, 1, str(content), content_style)
        current_row += 1

    # Figure ì„¹ì…˜
    if final_figures:
        current_row += 1
        ws1.write(current_row, 0, "ê·¸ë¦¼ (Figures)", header_style)
        ws1.write(current_row, 1, "â–¼ ì£¼ìš” ê·¸ë¦¼ ëª©ë¡", header_style)
        current_row += 1
        if current_row % 2 != 0: current_row += 1
        for item in final_figures:
            _write_row_dynamic(ws1, item, images, current_row, fig_style, content_style)
            current_row += 2

    # Table ì„¹ì…˜
    if final_tables:
        current_row += 1
        ws1.write(current_row, 0, "í‘œ (Tables)", header_style)
        ws1.write(current_row, 1, "â–¼ ì£¼ìš” í‘œ ëª©ë¡", header_style)
        current_row += 1
        if current_row % 2 != 0: current_row += 1
        for item in final_tables:
            _write_row_dynamic(ws1, item, images, current_row, tbl_style, content_style)
            current_row += 2

    workbook.close()
    output.seek(0)
    return output


def _write_row_dynamic(ws, item, images, row, label_fmt, content_fmt):
    clean_id = normalize_id(item.get('img_id'))
    target = next((img for img in images if img['id'] == clean_id), None)

    # í•œê¸€ ë¼ë²¨ ì ìš©
    final_label = item.get('korean_label', item.get('real_label', 'ê·¸ë¦¼'))
    caption_text = item.get('caption', 'ì„¤ëª… ì—†ìŒ')

    ws.write(row, 0, final_label, label_fmt)
    ws.write(row, 1, f"ğŸ“„ {caption_text}", content_fmt)

    img_row = row + 1

    if target:
        try:
            with Image.open(io.BytesIO(target['bytes'])) as img:
                w_px, h_px = img.size

            base_scale = 0.5
            display_h_px = h_px * base_scale
            row_height_pt = display_h_px * 0.75

            MAX_EXCEL_HEIGHT = 400
            final_scale = base_scale

            if row_height_pt > MAX_EXCEL_HEIGHT:
                row_height_pt = MAX_EXCEL_HEIGHT
                final_scale = (MAX_EXCEL_HEIGHT / 0.75) / h_px

            ws.set_row(img_row, row_height_pt)

            ws.insert_image(img_row, 1, f"{clean_id}.png", {
                'image_data': io.BytesIO(target['bytes']),
                'x_scale': final_scale,
                'y_scale': final_scale,
                'x_offset': 0, 'y_offset': 0,
                'object_position': 1
            })
        except:
            pass


# -----------------------------------------------------------
# [6] ì‹¤í–‰ ë¡œì§
# -----------------------------------------------------------

if 'analyzed_data' not in st.session_state:
    st.session_state.analyzed_data = None

paper_num = st.text_input("1. ë…¼ë¬¸ ë²ˆí˜¸ ì…ë ¥", value="1")
uploaded_file = st.file_uploader("2. PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

if uploaded_file and paper_num:
    if st.session_state.analyzed_data and st.session_state.analyzed_data['file_name'] != uploaded_file.name:
        st.session_state.analyzed_data = None

    if st.button("ë¶„ì„ ë° ì—‘ì…€ ë³€í™˜ ì‹œì‘"):
        if st.session_state.analyzed_data and st.session_state.analyzed_data['file_name'] == uploaded_file.name:
            st.success("âš¡ ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
        else:
            with st.spinner(f"[{SELECTED_MODEL_NAME}] ë¶„ì„ ì¤‘... (ì˜ì—­ ìº¡ì²˜ ëª¨ë“œ)"):
                try:
                    text, images, all_page_imgs = extract_data_from_pdf(uploaded_file)

                    if len(text.strip()) < 500:
                        st.warning("âš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ë¶ˆì•ˆì •í•˜ì—¬ ì „ì²´ í˜ì´ì§€ ë¶„ì„ì„ ë³‘í–‰í•©ë‹ˆë‹¤.")
                    else:
                        st.info(f"âœ… í…ìŠ¤íŠ¸ ë° {len(images)}ê°œì˜ ì£¼ìš” ì˜ì—­(Fig/Table) ì¶”ì¶œ ì™„ë£Œ!")

                    result = get_gemini_analysis(text, len(images), all_page_imgs)

                    if "error" in result:
                        st.error(f"AI ë¶„ì„ ì˜¤ë¥˜: {result['error']}")
                    else:
                        ref_imgs = result.get('referenced_images', [])
                        final_figs, final_tbls = [], []

                        for item in ref_imgs:
                            raw_label = item.get('real_label', 'Unknown')

                            # í•œê¸€ ë³€í™˜
                            detected_type, detected_num, korean_label = standardize_label_to_korean(raw_label)

                            item['sort_num'] = detected_num
                            item['korean_label'] = korean_label

                            if detected_type == "Table":
                                final_tbls.append(item)
                            else:
                                final_figs.append(item)

                        final_figs.sort(key=lambda x: x['sort_num'])
                        final_tbls.sort(key=lambda x: x['sort_num'])

                        st.session_state.analyzed_data = {
                            'file_name': uploaded_file.name,
                            'json': result,
                            'images': images,
                            'figs': final_figs,
                            'tbls': final_tbls
                        }
                        st.success("ì™„ë£Œ! ë¡œê³ ëŠ” ë²„ë¦¬ê³ , ì§„ì§œ ê·¸ë¦¼ê³¼ í‘œë§Œ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")

                except Exception as e:
                    st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")

    if st.session_state.analyzed_data:
        data = st.session_state.analyzed_data
        excel_data = create_excel(paper_num, data['json'], data['images'], data['figs'], data['tbls'])

        st.download_button(
            label="ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"Analysis_v6.6_{paper_num}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
