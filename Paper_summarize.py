import streamlit as st
import google.generativeai as genai
import fitz  # PyMuPDF
import xlsxwriter
import io
import json
import re
import os
import time
from PIL import Image

# -----------------------------------------------------------
# [1] í˜ì´ì§€ ì„¤ì •
# -----------------------------------------------------------
st.set_page_config(page_title="ë…¼ë¬¸ ë¶„ì„ Pro", layout="wide")

# -----------------------------------------------------------
# [2] ë©”ì¸ UI
# -----------------------------------------------------------
# ë²„ì „ ì—…ë°ì´íŠ¸: 5.8 -> 5.9
st.title("ğŸ“‘ ë…¼ë¬¸ ë¶„ì„ Pro [ver5.9]")
st.caption("âœ… ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸(Fig/Table) ë¶„ì„ | êµ¬ì¡° ë¶„ì„ ë³´ì™„")

# -----------------------------------------------------------
# [3] ì‚¬ì´ë“œë°”
# -----------------------------------------------------------
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    default_key = ''
    api_key_input = st.text_input("Google API Key", value=default_key, type="password")

    if not api_key_input:
        st.warning("ğŸ‘ˆ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()

    genai.configure(api_key=api_key_input, transport='rest')

    st.subheader("ğŸ¤– AI ëª¨ë¸ ì„ íƒ")
    try:
        available_models = []
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.replace('models/', '')
                available_models.append(name)

        preferred = ['gemini-1.5-flash', 'gemini-2.5-flash']
        available_models.sort(key=lambda x: (x not in preferred, x))

        if not available_models:
            st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        selected_model_name = st.selectbox(
            "âœ… ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡",
            available_models,
            index=0
        )
        SELECTED_MODEL_NAME = f"models/{selected_model_name}"
        st.success(f"ì—°ê²°ë¨: {selected_model_name}")

    except Exception as e:
        st.error(f"ëª¨ë¸ ëª©ë¡ ì˜¤ë¥˜: {e}")
        st.stop()

    # [ìˆ˜ì •ë¨] ë¶ˆí•„ìš”í•œ 'ì´ë¯¸ì§€ ì •ë°€ íŒë…' ì˜µì…˜ ë° ê´€ë ¨ UI ì œê±°

model = genai.GenerativeModel(SELECTED_MODEL_NAME)


# [ìˆ˜ì •ë¨] vision_model ì œê±° (ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)


# -----------------------------------------------------------
# [4] ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# -----------------------------------------------------------

def normalize_id(ref_text):
    """ì´ë¯¸ì§€ ID ì •ê·œí™”"""
    nums = re.findall(r'\d+', str(ref_text))
    return f"Image_{nums[0]}" if nums else None


def merge_nearby_rectangles(rects, distance=20):
    """ì‚¬ê°í˜• ë³‘í•© (ìŠ¤ë§ˆíŠ¸ ë¨¸ì§€)"""
    if not rects: return []
    rects.sort(key=lambda r: (r.y0, r.x0))
    merged = []
    while rects:
        current = rects.pop(0)
        has_merged = True
        while has_merged:
            has_merged = False
            rest = []
            for r in rects:
                expanded_current = fitz.Rect(current.x0 - distance, current.y0 - distance,
                                             current.x1 + distance, current.y1 + distance)
                if expanded_current.intersects(r):
                    current = current | r
                    has_merged = True
                else:
                    rest.append(r)
            rects = rest
        merged.append(current)
    return merged


# -----------------------------------------------------------
# [5] í•µì‹¬ ë¡œì§ í•¨ìˆ˜
# -----------------------------------------------------------

def extract_data_from_pdf(uploaded_file):
    pdf_bytes = uploaded_file.getvalue()
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")

    final_text_content = ""
    image_counter = 1

    all_captions = []
    all_images_info = []

    # 1. ì •ë³´ ìˆ˜ì§‘
    for page_num, page in enumerate(doc):
        text_blocks = page.get_text("blocks")
        for b in text_blocks:
            text = b[4].strip()
            # ìº¡ì…˜ í›„ë³´ ì‹ë³„
            if (text.startswith("Fig") or text.startswith("Table")) and len(text) < 500:
                bbox = fitz.Rect(b[0], b[1], b[2], b[3])
                cap_type = "Figure" if text.startswith("Fig") else "Table"
                label_match = re.match(r"(Fig\.?|Table)\s*\d+", text)
                label = label_match.group(0) if label_match else cap_type

                all_captions.append({
                    "page": page_num, "bbox": bbox, "text": text,
                    "type": cap_type, "label": label, "matched_img_id": None
                })

        image_list = page.get_images(full=True)
        raw_rects = []
        for img in image_list:
            xref = img[0]
            img_rects = page.get_image_rects(xref)
            for r in img_rects:
                if r.width < 10 or r.height < 10: continue
                raw_rects.append(r)

        merged_rects = merge_nearby_rectangles(raw_rects, distance=20)

        for rect in merged_rects:
            img_id = f"Image_{image_counter}"
            all_images_info.append({
                "id": img_id, "page": page_num, "bbox": rect, "matched_caption": None
            })
            image_counter += 1

    # 2. ìœ„ì¹˜ ê¸°ë°˜ ë§¤ì¹­ (ë³´ì¡°)
    for cap in all_captions:
        best_img = None
        min_score = float('inf')
        candidates = [img for img in all_images_info if img["page"] == cap["page"] and img["matched_caption"] is None]

        for img in candidates:
            # ë°©í–¥ ê·œì¹™
            if cap["type"] == "Figure" and cap["bbox"].y0 < img["bbox"].y1: continue
            if cap["type"] == "Table" and cap["bbox"].y1 > img["bbox"].y0: continue

            v_dist = max(0, cap["bbox"].y0 - img["bbox"].y1) if cap["type"] == "Figure" else max(0,
                                                                                                 img["bbox"].y0 - cap[
                                                                                                     "bbox"].y1)
            cap_center_x = (cap["bbox"].x0 + cap["bbox"].x1) / 2
            img_center_x = (img["bbox"].x0 + img["bbox"].x1) / 2
            h_align_dist = abs(cap_center_x - img_center_x)

            if h_align_dist > 150: continue

            total_score = v_dist + (h_align_dist * 2.5)
            if total_score < min_score:
                min_score = total_score
                best_img = img

        if best_img:
            cap["matched_img_id"] = best_img["id"]
            best_img["matched_caption"] = cap["label"]

    # 3. í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ì¶”ì¶œ
    extracted_images_map = {}
    for page_num, page in enumerate(doc):
        page_items = []
        text_blocks = page.get_text("blocks")
        for b in text_blocks:
            bbox = fitz.Rect(b[0], b[1], b[2], b[3])
            matched_cap = next((c for c in all_captions if c["page"] == page_num and c["bbox"] == bbox), None)
            text = b[4]
            if matched_cap and matched_cap["matched_img_id"]:
                text = text.strip() + f"\n[SYSTEM: Matches <<<<{matched_cap['matched_img_id']}>>>>]\n"
            page_items.append({"type": "text", "y0": b[1], "x0": b[0], "text": text})

        page_imgs = [img for img in all_images_info if img["page"] == page_num]
        for img_info in page_imgs:
            rect = img_info["bbox"]
            padding = 35
            clip_rect = fitz.Rect(rect.x0 - padding, rect.y0 - padding, rect.x1 + padding,
                                  rect.y1 + padding) & page.rect
            mat = fitz.Matrix(2, 2)
            pix = page.get_pixmap(matrix=mat, clip=clip_rect)
            img_bytes = pix.tobytes("png")

            img_id = img_info["id"]
            initial_label = img_info["matched_caption"] if img_info["matched_caption"] else "Unknown"

            marker_text = f"\n<<<<{img_id}>>>>\n"
            if img_info["matched_caption"]:
                marker_text = f"\n<<<<{img_id} (Matched with {initial_label})>>>>\n"

            page_items.append({
                "type": "image", "y0": rect.y0, "x0": rect.x0,
                "text": marker_text,
                "id": img_id, "bytes": img_bytes, "page": page_num + 1
            })

            if img_id not in extracted_images_map:
                extracted_images_map[img_id] = {
                    "id": img_id, "page": page_num + 1, "bytes": img_bytes,
                    "initial_label": initial_label
                }

        page_items.sort(key=lambda item: (item["y0"], item["x0"]))
        for item in page_items: final_text_content += item["text"]

    extracted_images = list(extracted_images_map.values())
    return final_text_content, extracted_images


def get_gemini_analysis(text, total_images):
    prompt = f"""
    ë„ˆëŠ” ë…¼ë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ ì½ê³  JSONìœ¼ë¡œ ì¶”ì¶œí•´.

    [ì§€ì‹œì‚¬í•­]
    1. **ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ë²ˆì—­.**
    2. ìš”ì•½(summary)ì€ 'ìµœì†Œ 2ë¬¸ì¥ ~ ìµœëŒ€ 5ë¬¸ì¥' ì‚¬ì´ë¡œ ì‘ì„±.
    3. **ì´ë¯¸ì§€ ë§¤ì¹­ ì‹œ, í…ìŠ¤íŠ¸ì— ìˆëŠ” `(Matched with ...)` ì •ë³´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ë”°ë¥¼ ê²ƒ.**

    [ìš”ì²­ í•­ëª©]
    0. title, author, affiliation, year, purpose
    1. ìš”ì•½ (intro, body, conclusion)
    2. key_images_desc, referenced_images

    [ì¶œë ¥ í¬ë§· JSON]
    {{
        "title": "...",
        "author": "...", "affiliation": "...", "year": "...", "purpose": "...",
        "intro_summary": "- ...", "body_summary": "- ...", "conclusion_summary": "- ...",
        "key_images_desc": "...",
        "referenced_images": [ {{ "img_id": "Image_5", "real_label": "Figure 1", "caption": "ì„¤ëª…" }} ]
    }}

    [í…ìŠ¤íŠ¸]:
    """ + text[:50000]

    try:
        response = model.generate_content(prompt, generation_config={"response_mime_type": "application/json"})
        return json.loads(response.text)
    except Exception as e:
        return {"error": str(e)}


def create_excel(paper_number, analysis_json, images, final_figures, final_tables):
    output = io.BytesIO()
    workbook = xlsxwriter.Workbook(output, {'in_memory': True})

    header_style = workbook.add_format(
        {'bold': True, 'bg_color': '#4472C4', 'font_color': 'white', 'border': 1, 'align': 'center',
         'valign': 'vcenter'})
    content_style = workbook.add_format({'text_wrap': True, 'valign': 'top', 'border': 1})
    fig_style = workbook.add_format(
        {'bold': True, 'valign': 'center', 'border': 1, 'bg_color': '#E7E6E6', 'align': 'center'})
    tbl_style = workbook.add_format(
        {'bold': True, 'valign': 'center', 'border': 1, 'bg_color': '#D9D9D9', 'align': 'center'})

    ws1 = workbook.add_worksheet("ë…¼ë¬¸ í•µì‹¬ ë¶„ì„")
    ws1.set_column('A:A', 25)
    ws1.set_column('B:B', 90)

    data_map = [
        ("No.", paper_number),
        ("ë…¼ë¬¸ ì œëª©", analysis_json.get('title', 'ì œëª© ì—†ìŒ')),
        ("ì €ì", analysis_json.get('author', '-')),
        ("ì €ì ì†Œì†", analysis_json.get('affiliation', '-')),
        ("ë°œí–‰ë…„ë„", analysis_json.get('year', '-')),
        ("ì—°êµ¬ ëª©ì ", analysis_json.get('purpose', '-')),
        ("ì„œë¡  ìš”ì•½", analysis_json.get('intro_summary', '-')),
        ("ë³¸ë¡  ìš”ì•½", analysis_json.get('body_summary', '-')),
        ("ê²°ë¡  ìš”ì•½", analysis_json.get('conclusion_summary', '-')),
        ("ì£¼ìš” í‘œ/ê·¸ë¦¼ ì„¤ëª…", analysis_json.get('key_images_desc', '-'))
    ]

    ws1.write(0, 0, "í•­ëª©", header_style)
    ws1.write(0, 1, "ë‚´ìš©", header_style)

    current_row = 1
    for label, content in data_map:
        ws1.write(current_row, 0, label, header_style)
        ws1.write(current_row, 1, content, content_style)
        current_row += 1

    # Figure ì„¹ì…˜
    if final_figures:
        current_row += 1
        ws1.write(current_row, 0, "Figures (ê·¸ë¦¼)", header_style)
        ws1.write(current_row, 1, "â–¼ ì£¼ìš” ê·¸ë¦¼ ëª©ë¡", header_style)
        current_row += 1
        if current_row % 2 != 0: current_row += 1
        for item in final_figures:
            _write_row_dynamic(ws1, item, images, current_row, fig_style, content_style)
            current_row += 2

            # Table ì„¹ì…˜
    if final_tables:
        current_row += 1
        ws1.write(current_row, 0, "Tables (í‘œ)", header_style)
        ws1.write(current_row, 1, "â–¼ ì£¼ìš” í‘œ ëª©ë¡", header_style)
        current_row += 1
        if current_row % 2 != 0: current_row += 1
        for item in final_tables:
            _write_row_dynamic(ws1, item, images, current_row, tbl_style, content_style)
            current_row += 2

    workbook.close()
    output.seek(0)
    return output


def _write_row_dynamic(ws, item, images, row, label_fmt, content_fmt):
    clean_id = normalize_id(item.get('img_id'))
    target = next((img for img in images if img['id'] == clean_id), None)

    ws.write(row, 0, item.get('real_label'), label_fmt)
    ws.write(row, 1, f"ğŸ“„ {item.get('caption')}", content_fmt)

    img_row = row + 1

    if target:
        try:
            with Image.open(io.BytesIO(target['bytes'])) as img:
                w_px, h_px = img.size

            base_scale = 0.5
            display_h_px = h_px * base_scale
            row_height_pt = display_h_px * 0.75

            MAX_EXCEL_HEIGHT = 400
            final_scale = base_scale

            if row_height_pt > MAX_EXCEL_HEIGHT:
                row_height_pt = MAX_EXCEL_HEIGHT
                final_scale = (MAX_EXCEL_HEIGHT / 0.75) / h_px

            ws.set_row(img_row, row_height_pt)

            ws.insert_image(img_row, 1, f"{clean_id}.png", {
                'image_data': io.BytesIO(target['bytes']),
                'x_scale': final_scale,
                'y_scale': final_scale,
                'x_offset': 0, 'y_offset': 0,
                'object_position': 1
            })
        except:
            pass


# -----------------------------------------------------------
# [6] ì‹¤í–‰ ë¡œì§
# -----------------------------------------------------------

if 'analyzed_data' not in st.session_state:
    st.session_state.analyzed_data = None

paper_num = st.text_input("1. ë…¼ë¬¸ ë²ˆí˜¸ ì…ë ¥", value="1")
uploaded_file = st.file_uploader("2. PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")

if uploaded_file and paper_num:
    if st.session_state.analyzed_data and st.session_state.analyzed_data['file_name'] != uploaded_file.name:
        st.session_state.analyzed_data = None

    if st.button("ë¶„ì„ ë° ì—‘ì…€ ë³€í™˜ ì‹œì‘"):
        if st.session_state.analyzed_data and st.session_state.analyzed_data['file_name'] == uploaded_file.name:
            st.success("âš¡ ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
        else:
            with st.spinner(f"[{SELECTED_MODEL_NAME}] ë¶„ì„ ì¤‘..."):
                try:
                    text, images = extract_data_from_pdf(uploaded_file)

                    # [ìˆ˜ì •ë¨] Vision OCR ê³¼ì • ì œê±° ë° ë°”ë¡œ Gemini ë¶„ì„ ìš”ì²­
                    result = get_gemini_analysis(text, len(images))

                    if "error" in result:
                        st.error(f"ì˜¤ë¥˜: {result['error']}")
                    else:
                        ref_imgs = result.get('referenced_images', [])
                        final_figs, final_tbls = [], []

                        # [ë¶„ë¥˜ ë¡œì§] Geminiì˜ í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼(real_label)ì—ë§Œ ì˜ì¡´
                        for item in ref_imgs:
                            label = item.get('real_label', 'Figure')

                            # 'Table' ë˜ëŠ” 'í‘œ'ë¼ëŠ” ë‹¨ì–´ê°€ ë“¤ì–´ê°€ë©´ í‘œë¡œ ë¶„ë¥˜
                            if "Table" in label or "í‘œ" in label:
                                final_tbls.append(item)
                            else:
                                final_figs.append(item)


                        def sort_key(x):
                            nums = re.findall(r'\d+', x.get('real_label', '0'))
                            return int(nums[0]) if nums else 999


                        final_figs.sort(key=sort_key)
                        final_tbls.sort(key=sort_key)

                        st.session_state.analyzed_data = {
                            'file_name': uploaded_file.name,
                            'json': result,
                            'images': images,
                            'figs': final_figs,
                            'tbls': final_tbls
                        }
                        st.success("ì™„ë£Œ! ë¶„ì„ì´ ëë‚¬ìŠµë‹ˆë‹¤.")

                except Exception as e:
                    st.error(f"ì˜¤ë¥˜: {e}")

    if st.session_state.analyzed_data:
        data = st.session_state.analyzed_data
        excel_data = create_excel(paper_num, data['json'], data['images'], data['figs'], data['tbls'])

        st.download_button(
            label="ğŸ“¥ ì—‘ì…€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=excel_data,
            file_name=f"Analysis_v5.9_{paper_num}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )